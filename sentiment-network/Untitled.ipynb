{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pdb\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, hidden_nodes = 10, learning_rate = 0.1):\n",
    "        np.random.seed(1)\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = 1\n",
    "        self.learning_rate = learning_rate\n",
    "        pdb.set_trace()\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        self.activation_function = sigmoid\n",
    "        \n",
    "    def MSE(self, y, Y):\n",
    "        return np.mean((y-Y)**2)\n",
    "    \n",
    "    def train(self, features, targets):\n",
    "        targets = np.array(targets)\n",
    "        m_records, m_features = features.shape\n",
    "        m_records = 128\n",
    "        pdb.set_trace()\n",
    "#         self.weight_input_to_hidden = np.zeros((m_features, self.hidden_nodes))\n",
    "        self.weight_input_to_hidden = np.random.normal(0.0, self.hidden_nodes**-0.5, \n",
    "                                            (m_features, self.hidden_nodes))\n",
    "#         self.weight_hidden_to_output = np.zeros((self.hidden_nodes, self.output_nodes))\n",
    "        self.weight_hidden_to_output = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                            (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        epochs = 1000\n",
    "        for i in np.arange(epochs):\n",
    "#             pdb.set_trace()\n",
    "#             batch = np.random.choice(list(targets).index, size=m_records)\n",
    "            batch = np.random.randint(features.shape[0], size=m_records)\n",
    "            X, y = features[batch, :], targets[batch]\n",
    "            # train data, test data, validation data\n",
    "#             X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "#             X_val, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "#             X, y = features, targets\n",
    "#             pdb.set_trace()\n",
    "            # forwardprop\n",
    "            hidden_layer_input = np.dot(X, self.weight_input_to_hidden) # hidden_layer_input(m_records, hidden_nodes)\n",
    "            hidden_layer_output = self.activation_function(hidden_layer_input) # hidden_layer_output(m_records, hidden_nodes)\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "            output_layer_input = np.dot(hidden_layer_output, self.weight_hidden_to_output) # output_layer_input(m_records, self.output_nodes)\n",
    "            output_layer_output = self.activation_function(output_layer_input)\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "            # backprop\n",
    "            output_error_term = (np.sum(y - output_layer_output) / m_records) * output_layer_output * (1 - output_layer_output)\n",
    "            del_w_hidden_to_output = output_error_term * hidden_layer_output\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "            hidden_error_term = np.dot(output_error_term, self.weight_hidden_to_output.T) * hidden_layer_output * (1 - hidden_layer_output)\n",
    "            del_w_input_to_hidden = np.dot(X.T, hidden_error_term)\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "            self.weight_input_to_hidden -= self.learning_rate * del_w_input_to_hidden / m_records\n",
    "            self.weight_hidden_to_output -= self.learning_rate * np.mean(del_w_hidden_to_output, axis=0)[:, None]\n",
    "            train_loss = self.predict(X, y)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress: {:2.1f}\".format(100 * i/float(epochs)) \\\n",
    "                            + \"% ... Training loss: \" + str(train_loss)[:5])\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        \n",
    "\n",
    "    def predict(self, X, y):\n",
    "        hidden_layer_input = np.dot(X, self.weight_input_to_hidden) # hidden_layer_input(m_records, hidden_nodes)\n",
    "        hidden_layer_output = self.activation_function(hidden_layer_input) # hidden_layer_output(m_records, hidden_nodes)\n",
    "        \n",
    "        output_layer_input = np.dot(hidden_layer_output, self.weight_hidden_to_output) # output_layer_input(m_records, self.output_nodes)\n",
    "        output_layer_output = self.activation_function(output_layer_input)\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "        error = self.MSE(output_layer_output, y)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pretty_print_review_and_label(i):\n",
    "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")\n",
    "\n",
    "g = open('reviews.txt','r') # What we know!\n",
    "reviews = list(map(lambda x:x[:-1],g.readlines()))\n",
    "g.close()\n",
    "\n",
    "g = open('labels.txt','r') # What we WANT to know!\n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()\n",
    "\n",
    "for index, review in enumerate(reviews):\n",
    "    words = review.split(' ')\n",
    "    if labels[index] == 'POSITIVE':\n",
    "        for word in words:\n",
    "            positive_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "    else:\n",
    "        for word in words:\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74074\n",
      "(25000, 74074)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(list(total_counts))\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)\n",
    "features = np.zeros((len(reviews), vocab_size))\n",
    "print(features.shape)\n",
    "word2index = {}\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word] = i\n",
    "word2index['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def update_input_layer(review, feature):\n",
    "    \"\"\" Modify the global layer_0 to represent the vector form of review.\n",
    "    The element at a given index of layer_0 should represent\n",
    "    how many times the given word occurs in the review.\n",
    "    Args:\n",
    "        review(string) - the string of the review\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # clear out previous state by resetting the layer to be all 0s\n",
    "    feature *= 0\n",
    "\n",
    "    # TODO: count how many times each word is used in the given review and store the results in layer_0 \n",
    "    global word2index\n",
    "    for word in review.split(' '):\n",
    "        feature[word2index[word]] += 1\n",
    "\n",
    "def get_target_for_label(label):\n",
    "    \"\"\"Convert a label to `0` or `1`.\n",
    "    Args:\n",
    "        label(string) - Either \"POSITIVE\" or \"NEGATIVE\".\n",
    "    Returns:\n",
    "        `0` or `1`.\n",
    "    \"\"\"\n",
    "    # TODO: Your code here\n",
    "    if label == 'NEGATIVE':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 74074)\n",
      "(25000, 1)\n"
     ]
    }
   ],
   "source": [
    "targets = np.zeros((len(reviews), 1))\n",
    "features = np.zeros((len(reviews), vocab_size))\n",
    "for i,review in enumerate(reviews):\n",
    "    update_input_layer(review, features[i])\n",
    "for i,target in enumerate(labels):\n",
    "    targets[i][0] = get_target_for_label(target)\n",
    "print(features.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-15-1fbe5775307d>(8)__init__()\n",
      "-> def sigmoid(x):\n",
      "(Pdb) c\n",
      "> <ipython-input-15-1fbe5775307d>(21)train()\n",
      "-> self.weight_input_to_hidden = np.random.normal(0.0, self.hidden_nodes**-0.5,\n",
      "(Pdb) c\n",
      "Progress: 99.9% ... Training loss: 0.452"
     ]
    }
   ],
   "source": [
    "# list(targets).index\n",
    "classifier = NeuralNetwork()\n",
    "classifier.train(features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = classifier.predict(features, targets)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(list(features).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch = np.random.randint(features.shape[0], size=m_records)\n",
    "            X, y = feature[np.random.randint(features.shape[0], size=m_records), :].values, targets[batch, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
